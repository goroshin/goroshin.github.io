<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
  <title>Ross Goroshin</title>
  <meta name="description" content="Academic Website">
  <meta name="author" content="Ross Goroshin">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="./css" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="./normalize.css">
  <link rel="stylesheet" href="./skeleton.css">
  <link rel="stylesheet" href="./custom.css">
  <link rel="stylesheet" href="./social-circles.min.css">


  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="SHORTCUT ICON" href="favicon.ico"/>
  <link rel="apple-touch-icon" href="favicon_apple.ico"/>

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

 <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href="#about">ABOUT</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#pubs">PROJECTS</a></li>
          <li class="navbar-item"><a class="navbar-link" href="#resume">RESUME</a></li>
        </ul>
      </div>
    </nav>


  <div class="container">
    <div class="row">
      <div class="one-half column" style="margin-top: 8.0%">
        <img class="bio-image" src="images/logo.jpeg" alt="">
      </div>
      <div class="one-half column" style="margin-top: 8.0%">
	    <br>
        <h2>Ross Goroshin</h2>
        <p>Research Scientist<br>
        <a class="project-link" href="https://scholar.google.com/citations?user=EC4o-1oAAAAJ&hl=en/" target="_blank">Google Scholar</a><br>
        <a href="https://github.com/goroshin/">Github</a><br>
	<a class="project-link" href="https://ca.linkedin.com/in/ross-goroshin-43277732/" target="_blank">LinkedIn</a><br>
        <a href="https://goroshin.github.io/">rgoroshin@gmail.com</a>
      </div>
    </div>

    <div class="row" style="margin-top: 7.5%" id="about">
      <p> I am a Research Scientist at <a href="https://research.google.com/teams/brain/">Google Brain</a> in Montreal, Canada. My research interests include computer vision and graphics, reinforcement learning, feature learning, unsupervised learning, meta-learning and robotics. Outside of research my interest are cycling, gaming, training a husky and growing grass [the latter two are eternal WIP].</p>
    </div>
  </div>



  <div class="container">
    <div class="row" style="margin-top: 2%" id="pubs">
      <h5>PROJECTS</h5>

    </div>
	
	<div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/tracking.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Comparing Transfer and Meta Learning Approaches on a Unified Few-Shot Classification Benchmark</b><br>
			  <em> Vincent Dumoulin, Neil Houlsby, Utku Evci, Xiaohua Zhai, <b>Ross Goroshin</b>, Sylvain Gelly, Hugo Larochelle </em><br/>
			  Submission
			  <a href=https://arxiv.org/abs/2104.02638>[paper]</a><br/>
			  This work presents a unified benchmark for few-shot learning and transfer learning. Popular methods from both communities are compared.   
			</p>
		</div>
    </div>

    <div class="row" style="margin-top: 2%" id="pubs">
      <h5>PROJECTS</h5>

    </div>
	
	<div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/tracking.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>An Analysis of Object Representations in Deep Visual Trackers</b><br>
			  <em>Ross Goroshin, Jonathan Tompson, Debidatta Dwibedi </em><br/>
			  Submission
			  <a href="https://arxiv.org/abs/2001.02593">[paper]</a><br/>
			  In this work we performed an in-depth analysis of a popular tracking architecture and suggested a novel architecture to mitigate saliency biases.
			</p>
		</div>
    </div>
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
			<img class="paper-image" src="images/meta2020.jpg" alt="">
		    <!--<video class="paper-image" src="images/top.mp4" autoplay loop playsinline muted></video>-->
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Meta-dataset: A dataset of datasets for learning to learn from few examples</b><br>
			  <em>Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci, Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, Hugo Larochelle</em><br/>
			  Submission ICLR 2020
			  <a href="https://arxiv.org/abs/1903.03096">[paper]</a>
			  <a href="https://github.com/google-research/meta-dataset/">[code]</a>
			  In this work we propose Meta-Dataset, a new benchmark for training and evaluating models that is large-scale, consists of diverse datasets, and presents more realistic tasks.
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/nature_2018.jpg" alt="">
		    <!--<video class="paper-image" src="images/8tasks1920x540_cropped.mp4" autoplay loop playsinline muted></video>-->
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Vector-based navigation using grid-like representations in artificial agents</b><br>
			  <em>Andrea Banino, Caswell Barry, Benigno Uria, Charles Blundell, Timothy Lillicrap, Piotr Mirowski, Alexander Pritzel, Martin J Chadwick, Thomas Degris, Joseph Modayil, Greg Wayne, Hubert Soyer, Fabio Viola, Brian Zhang, Ross Goroshin, Neil Rabinowitz, Razvan Pascanu, Charlie Beattie, Stig Petersen, Amir Sadik, Stephen Gaffney, Helen King, Koray Kavukcuoglu, Demis Hassabis, Raia Hadsell, Dharshan Kumaran</em><br/>
			  Nature 2018
			  <a href="https://www.nature.com/articles/s41586-018-0102-6">[paper]</a>
			  We set out to leverage the computational functions of grid cells to develop a deep reinforcement learning agent with mammal-like navigational abilities.
			</p>
		</div>
    </div>	
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/learninng_navigate_2017.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Learning to navigate in complex environments</b><br>
			  <em>Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew J Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, Dharshan Kumaran, Raia Hadsell</em><br/>
			  ICLR 2017
			  <a href="https://arxiv.org/abs/1611.03673">[paper]</a>
			  In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks leveraging multimodal sensory inputs.
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/auto_encoders.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Stacked What-Where Auto-encoders</b><br>
			  <em>Junbo Zhao, Michael Mathieu, Ross Goroshin, Yann LeCun</em><br/>
			  ICLR 2016
			  <a href="https://arxiv.org/abs/1506.02351">[paper]</a><br/>
			  We present a novel architecture, the stacked what-where auto-encoders (SWWAE), which integrates discriminative and generative pathways and provides a unified approach to supervised, semi-supervised and unsupervised learning without relying on sampling during training.
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/phd_diss.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Unsupervised Feature Learning in Computer Vision</b><br>
			  <em>Ross Goroshin</em><br/>
			  NYU PhD dissertation 2015
			  <a href="https://www.math.nyu.edu/media/mathfin/publications/goroshin_ross.pdf">[paper]</a>
			  This work aims to uncover the principles that lead to these generic feature representations in the unsupervised setting, which does not require problem specific label information.
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/uncertainty.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Learning to linearize under uncertainty</b><br>
			  <em>R Goroshin, MF Mathieu, Y LeCun</em><br/>
			  Advances in NIPS 2015
			  <a href="http://papers.nips.cc/paper/5951-learning-to-linearize-under-uncertainty">[paper]</a><br/>
			  In this work we suggest a new architecture and loss for training deep feature hierarchies that linearize the transformations observed in unlabeled natural video sequences.
			</p>
		</div>
    </div>	
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/spatiotemporal.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Unsupervised learning of spatiotemporally coherent metrics</b><br>
			  <em>Ross Goroshin, Joan Bruna, Jonathan Tompson, David Eigen, Yann LeCun</em><br/>
			  ICCV 2015
			  <a href="http://openaccess.thecvf.com/content_iccv_2015/html/Goroshin_Unsupervised_Learning_of_ICCV_2015_paper.html">[paper]</a>
			  We focus on feature learning from unlabeled video data, using the assumption that adjacent video frames contain semantically similar information. We establish a connection between slow feature learning and metric learning. 
			</p>
		</div>
    </div>
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/cvpr_2014_model.jpg" alt=""><br>
			<img class="paper-image" src="images/cvpr_2014_detections.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Efﬁcient Object Localization Using Convolutional Networks</b><br>
			  <em>Jonathan Tompson, Ross Goroshin, Arjun Jain, Yann LeCun, Christoph Bregler</em><br/>
			  CVPR 2015
			  <a href="others/tompson_cvpr15.pdf">[paper]</a>
			  <a href="data/flic_predictions_cvpr.zip">[predictions_flic]</a>
			  <a href="data/mpii_test_pred.zip">[predictions_mpii]</a><br/>
			  A novel cascaded architecture to help overcome the effects of MaxPooling and a modified dropout that works better in the presence of spatially-coherent activations. Achieved SoTA in human body tracking.<br>
			  Turked MPII images containing one person: <a href="data/single_person_list_MPII.txt">[data]</a>.
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/satae.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Saturating auto-encoders</b><br>
			  <em>Ross Goroshin, Yann LeCun</em><br/>
			  2013
			  <a href="https://arxiv.org/abs/1301.3577">[paper]</a>
			  We introduce a simple new regularizer for auto-encoders (SATAE) whose hidden-unit activation functions contain at least one zero-gradient (saturated) region.
			</p>
		</div>
    </div>
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/features.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Unsupervised Feature Learning from Temporal Data</b><br>
			  <em>Ross Goroshin, Joan Bruna, Jonathan Tompson, Arthur Szlam, David Eigen, Yann LeCun</em><br/>
			  ACCV 2014
			  <a href="others/nips2014_workshop_ross.pdf">[paper]</a><br/>
			  A sparse auto-encoder architecture to make use of temporal coherence. This formulation enables pre-training on unlabeled video data (of which there is a massive abundance), to improve ConvNet performance.
			</p>
		</div>

    </div>	
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/visibility_opt.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Approximate solutions to several visibility optimization problems</b><br>
			  <em>Ross Goroshin, Quyen Huynh, Hao-Min Zhou</em><br/>
			  Communications in Mathematical Sciences 2011
			  <a href="https://www.intlpress.com/site/pub/pages/journals/items/cms/content/vols/0009/0002/a009/">[paper]</a>
			  A learning-based system for simulating Navier-Stokes Equations in real-time. We do so by reformulating the standard operator splitting method as an end-to-end network.
			</p>
		</div>
    </div>		
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/tracking_cables.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Tracking cables in sonar and optical imagery</b><br>
			  <em>Jason C Isaacs, Ross Goroshin</em><br/>
			  IEEE 2010
			  <a href="https://ieeexplore.ieee.org/abstract/document/5759686/">[paper]</a>
			  In this paper we present an "upgraded" and ultimately more robust approach to line detection in images.
			</p>
		</div>
    </div>	
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/masters.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Obstacle detection using a monocular camera</b><br>
			  GeorgiaTech Master's thesis 2018
			  <a href="https://smartech.gatech.edu/handle/1853/24697">[thesis]</a>
			  The objective of my thesis is to develop a general obstacle segmentation algorithm for use on board a ground based unmanned vehicle (GUV).
			</p>
		</div>
    </div>	
	
    <div class="row">
        <div class="five columns" style="margin-top: 2%">
		    <img class="paper-image" src="images/cvpr_2014_model.jpg" alt=""><br>
			<img class="paper-image" src="images/cvpr_2014_detections.jpg" alt="">
        </div>
        <div class="seven columns" style="margin-top: 2%">
			<p>
			  <b>Efﬁcient Object Localization Using Convolutional Networks</b><br>
			  <em>Jonathan Tompson, Ross Goroshin, Arjun Jain, Yann LeCun, Christoph Bregler</em><br/>
			  CVPR 2015
			  <a href="others/tompson_cvpr15.pdf">[paper]</a>
			  <a href="data/flic_predictions_cvpr.zip">[predictions_flic]</a>
			  <a href="data/mpii_test_pred.zip">[predictions_mpii]</a><br/>
			  A novel cascaded architecture to help overcome the effects of MaxPooling and a modified dropout that works better in the presence of spatially-coherent activations. Achieved SoTA in human body tracking.<br>
			  Turked MPII images containing one person: <a href="data/single_person_list_MPII.txt">[data]</a>.
			</p>
		</div>
   
    </div>		
	
    <div class="row">
        <div class="ten columns" style="margin-top: 2%">
			<p style="margin-bottom: 0.5rem">
			  <b>Open Source Tools</b><br>
			  [here goes a list of the tools I've written or contributed over the years]:
			  <ul>
				  <li><a href="https://github.com/goroshin" class="link">1</a></li>
				  <li><a href="https://github.com/goroshin" class="link">2</a></li>
				  <li><a href="https://github.com/goroshin" class="link">3..</a></li>	

			  </ul>
			</p>
		</div>
    </div>	
	
  </div>
  
  <div class="container">

    <div class="row" style="margin-top: 2%" id="resume">
      <h4>Resume</h4>
    </div>
	
	<div class="row">
	    <p style="margin-bottom: 0rem">
	        <a href="resume/ross_cv.pdf" style="text-decoration: none"><img  src="images/pfd.gif" height="30" alt=""/></a><a href="https://github.com/goroshin">PDF</a> 
	        <br />
	    </p>
	    <div class="twelve columns" style="margin-top: 2%">
		    <!--Used https://www.zamzar.com/convert/pdf-to-svg/ to convert pdf to svg-->
		    <img class="paper-image" src="resume/ross_cv_p1.svg" style="Border: 1px solid black;" alt="">
			<img class="paper-image" src="resume/ross_cv_p2.svg" style="Border: 1px solid black;" alt="">
		    <!--<embed src="resume/ross_cv.pdf" width="500" height="375" type="application/pdf">-->
	        <!--<iframe src="resume/ross_cv.pdf" 
style="width:900px; height:2150px;" frameborder="0">Embedded pdf not supported by your browser.  Please click the download link above.</iframe>-->
	    </div>
		<br/>
	</div>
	
  </div>	

<br>
<br>
<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->


</body></html>
